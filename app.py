import streamlit as st
import google.generative_ai as genai
import os
import glob

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="å®Œå…¨è‡ªå‹•ãƒ»ç¨å‹™AI", layout="wide")

# APIã‚­ãƒ¼ã®è¨­å®šï¼ˆStreamlitã®Secretsã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼‰
# â€»ã‚ã¨ã§è¨­å®šã—ã¾ã™
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# ãƒ¢ãƒ‡ãƒ«è¨­å®š (ç„¡æ–™æ ãªã‚‰ flash ã‚’æ¨å¥¨)
MODEL_NAME = "gemini-1.5-flash"

def load_data():
    """dataãƒ•ã‚©ãƒ«ãƒ€å†…ã®Markdownã‚’å…¨éƒ¨èª­ã¿è¾¼ã‚€"""
    all_text = ""
    # dataãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å†å¸°çš„ã«æ¢ã™å ´åˆãªã©èª¿æ•´å¯èƒ½
    # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã« dataãƒ•ã‚©ãƒ«ãƒ€ç›´ä¸‹ ã¾ãŸã¯ data/ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€/*.md ã‚’æƒ³å®š
    files = glob.glob("data/**/*.md", recursive=True)
    
    if not files:
        return "ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    for file in files:
        with open(file, "r", encoding="utf-8") as f:
            all_text += f"\n\n--- FILE: {os.path.basename(file)} ---\n"
            all_text += f.read()
    return all_text

st.title("ğŸ¤– å®Œå…¨è‡ªå‹•ãƒ»ç¨å‹™AI (Free Edition)")
st.caption("æ¯é€±è‡ªå‹•æ›´æ–°ã•ã‚Œã‚‹å›½ç¨åºãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚‚è‰¯ã„ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ã«æ¯å›èª­ã‚€ï¼‰
context_data = load_data()

# ãƒãƒ£ãƒƒãƒˆç”»é¢ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šä¿®ç¹•è²»ã®åˆ¤æ–­åŸºæº–ã¯ï¼Ÿï¼‰"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIã®å›ç­”ç”Ÿæˆ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + ãƒ‡ãƒ¼ã‚¿ + ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            model = genai.GenerativeModel(
                MODEL_NAME,
                system_instruction=f"ã‚ãªãŸã¯ç¨å‹™ã®å°‚é–€å®¶AIã§ã™ã€‚ä»¥ä¸‹ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\nã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘\n{context_data}"
            )
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å›ç­”è¡¨ç¤º
            full_response = ""
            response = model.generate_content(prompt, stream=True)
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            # å±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
